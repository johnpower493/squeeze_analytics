{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze Analytics â€” EDA (SQLite)\n",
    "\n",
    "This notebook does initial exploratory data analysis (EDA) directly from your local `ohlc.sqlite3` file.\n",
    "\n",
    "Focus:\n",
    "- Load key tables (`ohlc`, `alerts`, `trade_plans`)\n",
    "- Normalize epoch timestamps (ms)\n",
    "- Convert all timestamps to **Australia/Sydney** (AEDT/AEST automatically depending on date)\n",
    "- Basic sanity checks, missing data, distributions\n",
    "\n",
    "Notes:\n",
    "- SQLite stores timestamps as integers (often milliseconds).\n",
    "- `Australia/Sydney` handles DST transitions for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "DB_PATH = Path('ohlc.sqlite3')\n",
    "assert DB_PATH.exists(), f'Missing DB file: {DB_PATH.resolve()}'\n",
    "TZ = 'Australia/Sydney'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers: timestamp normalization + timezone conversion\n",
    "\n",
    "Your DB uses integers like `1768313070803` which are **epoch milliseconds**.\n",
    "\n",
    "We convert to UTC first (`utc=True`), then convert to Sydney time.\n",
    "Sydney will automatically show AEST vs AEDT depending on the date." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_utc_datetime(ts: pd.Series | np.ndarray | list, unit: str = 'ms') -> pd.Series:\n",
    "    \"\"\"Convert an epoch timestamp series to timezone-aware UTC datetimes.\n",
    "\n",
    "    unit: 'ms' for epoch milliseconds, 's' for seconds.\n",
    "    \"\"\"\n",
    "    s = pd.Series(ts)\n",
    "    # best-effort numeric coercion\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    return pd.to_datetime(s, unit=unit, utc=True)\n",
    "\n",
    "\n",
    "def utc_to_sydney(dt_utc: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert a tz-aware UTC datetime series to Australia/Sydney time.\"\"\n",
    "    if getattr(dt_utc.dt, 'tz', None) is None:\n",
    "        raise ValueError('Expected tz-aware series (UTC). Use to_utc_datetime(..., utc=True).')\n",
    "    return dt_utc.dt.tz_convert(TZ)\n",
    "\n",
    "\n",
    "def add_sydney_time(df: pd.DataFrame, col: str, unit: str = 'ms', prefix: str | None = None) -> pd.DataFrame:\n",
    "    \"\"\"Add UTC + Sydney datetime columns derived from an epoch timestamp column.\n",
    "\n",
    "    Adds: <prefix>_dt_utc, <prefix>_dt_syd\n",
    "    \"\"\"\n",
    "    if prefix is None:\n",
    "        prefix = col\n",
    "    out = df.copy()\n",
    "    out[f'{prefix}_dt_utc'] = to_utc_datetime(out[col], unit=unit)\n",
    "    out[f'{prefix}_dt_syd'] = utc_to_sydney(out[f'{prefix}_dt_utc'])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List tables and row counts" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\", conn)\n",
    "    display(tables)\n",
    "\n",
    "    counts = []\n",
    "    for t in tables['name'].tolist():\n",
    "        n = pd.read_sql_query(f\"SELECT COUNT(*) AS n FROM {t}\", conn)['n'].iloc[0]\n",
    "        counts.append((t, int(n)))\n",
    "    counts_df = pd.DataFrame(counts, columns=['table','rows']).sort_values('rows', ascending=False)\n",
    "    display(counts_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OHLC sample\n",
    "\n",
    "The `ohlc` table usually contains `open_time` and `close_time` in epoch ms." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    ohlc = pd.read_sql_query(\"SELECT * FROM ohlc LIMIT 50000\", conn)\n",
    "\n",
    "ohlc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numeric columns\n",
    "for c in ['open','high','low','close','volume']:\n",
    "    if c in ohlc.columns:\n",
    "        ohlc[c] = pd.to_numeric(ohlc[c], errors='coerce')\n",
    "\n",
    "# Add timezone-aware datetimes\n",
    "if 'open_time' in ohlc.columns:\n",
    "    ohlc = add_sydney_time(ohlc, 'open_time', unit='ms', prefix='open')\n",
    "if 'close_time' in ohlc.columns:\n",
    "    ohlc = add_sydney_time(ohlc, 'close_time', unit='ms', prefix='close')\n",
    "\n",
    "ohlc[['exchange','symbol','interval','open_time','open_dt_utc','open_dt_syd','close_time','close_dt_syd']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic sanity checks" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc.isna().mean().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc[['open','high','low','close','volume']].describe(percentiles=[0.01,0.05,0.5,0.95,0.99]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Alerts + Trade Plans\n",
    "The `alerts` and `trade_plans` tables are often the best starting point for strategy exploration." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    alerts = pd.read_sql_query(\"SELECT * FROM alerts LIMIT 200000\", conn)\n",
    "    trade_plans = pd.read_sql_query(\"SELECT * FROM trade_plans LIMIT 200000\", conn)\n",
    "\n",
    "alerts.shape, trade_plans.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp columns found in these tables\n",
    "for col in ['ts','created_ts']:\n",
    "    if col in alerts.columns:\n",
    "        alerts = add_sydney_time(alerts, col, unit='ms', prefix=col)\n",
    "\n",
    "if 'ts' in trade_plans.columns:\n",
    "    trade_plans = add_sydney_time(trade_plans, 'ts', unit='ms', prefix='ts')\n",
    "\n",
    "alerts[['exchange','symbol','signal','source_tf','ts','ts_dt_syd']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert distributions" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts['signal'].value_counts(dropna=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts['source_tf'].value_counts(dropna=False).head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-of-day / day-of-week in Sydney time\n",
    "If you want to understand session effects, always compute these features *after* timezone conversion." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts['hour_syd'] = alerts['ts_dt_syd'].dt.hour\n",
    "alerts['dow_syd'] = alerts['ts_dt_syd'].dt.day_name()\n",
    "\n",
    "display(alerts['dow_syd'].value_counts())\n",
    "display(alerts['hour_syd'].value_counts().sort_index().head(24))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Spark / Databricks SQL examples (Sydney time)\n",
    "If you end up loading these tables into Databricks, here are equivalent conversions." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark example (Databricks / PySpark)\n",
    "# from pyspark.sql import functions as F\n",
    "# df = spark.table('ohlc')\n",
    "# df = df.withColumn('open_ts_utc', (F.col('open_time')/1000).cast('timestamp'))\n",
    "# # Interpret as UTC then convert to Sydney\n",
    "# df = df.withColumn('open_time_syd', F.from_utc_timestamp(F.col('open_ts_utc'), 'Australia/Sydney'))\n",
    "# display(df.select('exchange','symbol','interval','open_time','open_time_syd').limit(10))\n",
    "\n",
    "# SQL example:\n",
    "# %sql\n",
    "# SELECT\n",
    "#   exchange, symbol, interval,\n",
    "#   open_time,\n",
    "#   from_utc_timestamp(to_timestamp(open_time/1000), 'Australia/Sydney') AS open_time_syd\n",
    "# FROM ohlc\n",
    "# LIMIT 10;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
