{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databricks â€” Momentum Swing Backtest (Clean Universe + Parameter Grid + Regimes)\n",
    "\n",
    "This notebook is the main engine for **pattern recognition + backtesting**.\n",
    "\n",
    "It includes:\n",
    "- Single-symbol iteration (fast debugging)\n",
    "- Multi-symbol backtest at scale using Spark `groupBy(...).applyInPandas(...)`\n",
    "- Universe sourced from `clean_universe` (generated by `databricks_eda_sydney_time.ipynb`)\n",
    "- A small parameter grid (stop/TP/hold)\n",
    "- ATR% regime buckets recorded per trade\n",
    "\n",
    "Timezone:\n",
    "- We compute UTC timestamps from epoch ms for correct ordering.\n",
    "- We add Sydney timestamps (AEST/AEDT) for reporting, not for trading logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG `workspace`;\n",
    "USE SCHEMA `squeeze`;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "TZ = 'Australia/Sydney'\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "print('RUN_ID =', RUN_ID)\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 140)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy definition\n",
    "Start with one simple momentum pattern, then iterate based on results." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BacktestParams:\n",
    "    atr_mult_stop: float\n",
    "    atr_mult_tp: float\n",
    "    max_hold_bars: int\n",
    "\n",
    "# Small parameter grid to start (expand later)\n",
    "PARAM_GRID = [\n",
    "    BacktestParams(atr_mult_stop=1.5, atr_mult_tp=2.5, max_hold_bars=48),\n",
    "    BacktestParams(atr_mult_stop=2.0, atr_mult_tp=3.0, max_hold_bars=48),\n",
    "    BacktestParams(atr_mult_stop=2.5, atr_mult_tp=3.5, max_hold_bars=72),\n",
    "]\n",
    "\n",
    "SIGNALS = ['sig_breakout_long']\n",
    "DEFAULT_PARAMS = PARAM_GRID[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers: features + signals" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(s: pd.Series, span: int) -> pd.Series:\n",
    "    return s.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def atr(high: pd.Series, low: pd.Series, close: pd.Series, n: int = 14) -> pd.Series:\n",
    "    prev_close = close.shift(1)\n",
    "    tr = pd.concat([(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
    "    return tr.rolling(n, min_periods=n).mean()\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out['ema_20'] = ema(out['close'], 20)\n",
    "    out['ema_50'] = ema(out['close'], 50)\n",
    "    out['trend_up'] = out['ema_20'] > out['ema_50']\n",
    "    out['atr_14'] = atr(out['high'], out['low'], out['close'], 14)\n",
    "    out['atrp_14'] = out['atr_14'] / out['close']\n",
    "    L = 20\n",
    "    out['hh_20'] = out['high'].rolling(L, min_periods=L).max()\n",
    "    return out\n",
    "\n",
    "def add_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # Trend + breakout above prior high (use shift to avoid lookahead)\n",
    "    out['sig_breakout_long'] = out['trend_up'] & (out['close'] > out['hh_20'].shift(1))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest core (pandas)" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_long(df: pd.DataFrame, signal_col: str, p: BacktestParams) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    n = len(df)\n",
    "    for i in range(n - 2):\n",
    "        if not bool(df[signal_col].iloc[i]):\n",
    "            continue\n",
    "        entry_i = i + 1\n",
    "        entry = float(df['open'].iloc[entry_i])\n",
    "        atrv = float(df['atr_14'].iloc[entry_i])\n",
    "        if not np.isfinite(entry) or not np.isfinite(atrv) or atrv <= 0:\n",
    "            continue\n",
    "        stop = entry - p.atr_mult_stop * atrv\n",
    "        tp = entry + p.atr_mult_tp * atrv\n",
    "        last_i = min(n - 1, entry_i + p.max_hold_bars)\n",
    "\n",
    "        exit_i = None\n",
    "        exit_px = None\n",
    "        outcome = None\n",
    "\n",
    "        # conservative bar model: stop before tp within bar\n",
    "        for j in range(entry_i, last_i + 1):\n",
    "            lo = float(df['low'].iloc[j])\n",
    "            hi = float(df['high'].iloc[j])\n",
    "            if lo <= stop:\n",
    "                exit_i, exit_px, outcome = j, stop, 'stop'\n",
    "                break\n",
    "            if hi >= tp:\n",
    "                exit_i, exit_px, outcome = j, tp, 'tp'\n",
    "                break\n",
    "\n",
    "        if exit_i is None:\n",
    "            exit_i, exit_px, outcome = last_i, float(df['close'].iloc[last_i]), 'time'\n",
    "\n",
    "        r = (exit_px - entry) / (entry - stop) if (entry - stop) != 0 else np.nan\n",
    "        atrp_entry = float(df['atrp_14'].iloc[entry_i]) if 'atrp_14' in df.columns else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            'entry_i': int(entry_i),\n",
    "            'exit_i': int(exit_i),\n",
    "            'entry_time_utc': df['open_dt_utc'].iloc[entry_i],\n",
    "            'entry_time_syd': df['open_dt_syd'].iloc[entry_i],\n",
    "            'exit_time_utc': df['open_dt_utc'].iloc[exit_i],\n",
    "            'entry': entry,\n",
    "            'stop': stop,\n",
    "            'tp': tp,\n",
    "            'exit': exit_px,\n",
    "            'bars_held': int(exit_i - entry_i),\n",
    "            'outcome': outcome,\n",
    "            'r_multiple': float(r),\n",
    "            'atrp_entry': atrp_entry,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-symbol iteration (optional)\n",
    "Use this to debug strategy logic quickly." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCHANGE = 'binance'\n",
    "SYMBOL = 'BTCUSDT'\n",
    "INTERVAL = '1h'\n",
    "LIMIT_ROWS = 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc_s = (spark.table('ohlc')\n",
    "  .where((F.col('exchange')==EXCHANGE) & (F.col('symbol')==SYMBOL) & (F.col('interval')==INTERVAL))\n",
    "  .select('exchange','symbol','interval','open_time','open','high','low','close','volume')\n",
    "  .withColumn('open_dt_utc', F.to_timestamp(F.col('open_time')/1000))\n",
    "  .withColumn('open_dt_syd', F.from_utc_timestamp(F.col('open_dt_utc'), TZ))\n",
    "  .orderBy('open_time')\n",
    "  .limit(LIMIT_ROWS)\n",
    ")\n",
    "df = ohlc_s.toPandas()\n",
    "for c in ['open','high','low','close','volume']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "df = df.sort_values('open_time').reset_index(drop=True)\n",
    "df = add_signals(add_features(df))\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regime buckets on the full series\n",
    "try:\n",
    "    df['atrp_bucket'] = pd.qcut(df['atrp_14'], q=5, labels=['Q1_low','Q2','Q3','Q4','Q5_high'])\n",
    "except Exception:\n",
    "    df['atrp_bucket'] = None\n",
    "\n",
    "tr = backtest_long(df, 'sig_breakout_long', DEFAULT_PARAMS)\n",
    "tr['atrp_bucket'] = [str(df['atrp_bucket'].iloc[i]) if i < len(df) else None for i in tr['entry_i']]\n",
    "display(tr.head(50))\n",
    "display(tr['outcome'].value_counts())\n",
    "display(tr['r_multiple'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-symbol backtest (Spark applyInPandas)\n",
    "Universe is read from `clean_universe`." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIVERSE_INTERVAL = '1h'\n",
    "UNIVERSE_LIMIT = 200  # set None for full clean_universe\n",
    "\n",
    "universe = (spark.table('clean_universe')\n",
    "  .where(F.col('interval') == UNIVERSE_INTERVAL)\n",
    "  .select('exchange','symbol','interval')\n",
    ")\n",
    "if UNIVERSE_LIMIT is not None:\n",
    "    universe = universe.limit(int(UNIVERSE_LIMIT))\n",
    "\n",
    "display(universe)\n",
    "print('Universe size:', universe.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_schema = T.StructType([\n",
    "  T.StructField('run_id', T.StringType(), False),\n",
    "  T.StructField('exchange', T.StringType(), True),\n",
    "  T.StructField('symbol', T.StringType(), True),\n",
    "  T.StructField('interval', T.StringType(), True),\n",
    "  T.StructField('signal', T.StringType(), True),\n",
    "  T.StructField('atr_mult_stop', T.DoubleType(), True),\n",
    "  T.StructField('atr_mult_tp', T.DoubleType(), True),\n",
    "  T.StructField('max_hold_bars', T.IntegerType(), True),\n",
    "  T.StructField('atrp_entry', T.DoubleType(), True),\n",
    "  T.StructField('atrp_bucket', T.StringType(), True),\n",
    "  T.StructField('entry_time_utc', T.TimestampType(), True),\n",
    "  T.StructField('entry_time_syd', T.TimestampType(), True),\n",
    "  T.StructField('exit_time_utc', T.TimestampType(), True),\n",
    "  T.StructField('entry', T.DoubleType(), True),\n",
    "  T.StructField('stop', T.DoubleType(), True),\n",
    "  T.StructField('tp', T.DoubleType(), True),\n",
    "  T.StructField('exit', T.DoubleType(), True),\n",
    "  T.StructField('bars_held', T.IntegerType(), True),\n",
    "  T.StructField('outcome', T.StringType(), True),\n",
    "  T.StructField('r_multiple', T.DoubleType(), True),\n",
    "])\n",
    "\n",
    "def backtest_group(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    if pdf.empty:\n",
    "        return pd.DataFrame(columns=[f.name for f in trade_schema.fields])\n",
    "\n",
    "    pdf = pdf.sort_values('open_time').reset_index(drop=True)\n",
    "    for c in ['open','high','low','close','volume']:\n",
    "        pdf[c] = pd.to_numeric(pdf[c], errors='coerce')\n",
    "\n",
    "    pdf['open_dt_utc'] = pd.to_datetime(pd.to_numeric(pdf['open_time'], errors='coerce'), unit='ms', utc=True)\n",
    "    pdf['open_dt_syd'] = pdf['open_dt_utc'].dt.tz_convert(TZ)\n",
    "\n",
    "    pdf = add_signals(add_features(pdf))\n",
    "\n",
    "    try:\n",
    "        pdf['atrp_bucket'] = pd.qcut(pdf['atrp_14'], q=5, labels=['Q1_low','Q2','Q3','Q4','Q5_high'])\n",
    "    except Exception:\n",
    "        pdf['atrp_bucket'] = None\n",
    "\n",
    "    out_rows = []\n",
    "    ex = pdf['exchange'].iloc[0] if 'exchange' in pdf.columns else None\n",
    "    sym = pdf['symbol'].iloc[0] if 'symbol' in pdf.columns else None\n",
    "    itv = pdf['interval'].iloc[0] if 'interval' in pdf.columns else None\n",
    "\n",
    "    for sig in SIGNALS:\n",
    "        for p in PARAM_GRID:\n",
    "            tr = backtest_long(pdf, sig, p)\n",
    "            if tr.empty:\n",
    "                continue\n",
    "            tr['atrp_bucket'] = [str(pdf['atrp_bucket'].iloc[i]) if i < len(pdf) else None for i in tr['entry_i']]\n",
    "            tr.insert(0, 'r_multiple', tr['r_multiple'])  # no-op, ensure column exists\n",
    "\n",
    "            tr.insert(0, 'outcome', tr['outcome'])\n",
    "            tr.insert(0, 'bars_held', tr['bars_held'])\n",
    "            tr.insert(0, 'exit', tr['exit'])\n",
    "            tr.insert(0, 'tp', tr['tp'])\n",
    "            tr.insert(0, 'stop', tr['stop'])\n",
    "            tr.insert(0, 'entry', tr['entry'])\n",
    "            tr.insert(0, 'exit_time_utc', tr['exit_time_utc'])\n",
    "            tr.insert(0, 'entry_time_syd', tr['entry_time_syd'])\n",
    "            tr.insert(0, 'entry_time_utc', tr['entry_time_utc'])\n",
    "\n",
    "            tr.insert(0, 'atrp_bucket', tr['atrp_bucket'])\n",
    "            tr.insert(0, 'atrp_entry', tr['atrp_entry'])\n",
    "            tr.insert(0, 'max_hold_bars', int(p.max_hold_bars))\n",
    "            tr.insert(0, 'atr_mult_tp', float(p.atr_mult_tp))\n",
    "            tr.insert(0, 'atr_mult_stop', float(p.atr_mult_stop))\n",
    "            tr.insert(0, 'signal', sig)\n",
    "            tr.insert(0, 'interval', itv)\n",
    "            tr.insert(0, 'symbol', sym)\n",
    "            tr.insert(0, 'exchange', ex)\n",
    "            tr.insert(0, 'run_id', RUN_ID)\n",
    "\n",
    "            out_rows.append(tr[[\n",
    "                'run_id','exchange','symbol','interval','signal',\n",
    "                'atr_mult_stop','atr_mult_tp','max_hold_bars',\n",
    "                'atrp_entry','atrp_bucket',\n",
    "                'entry_time_utc','entry_time_syd','exit_time_utc',\n",
    "                'entry','stop','tp','exit','bars_held','outcome','r_multiple'\n",
    "            ]])\n",
    "\n",
    "    if not out_rows:\n",
    "        return pd.DataFrame(columns=[f.name for f in trade_schema.fields])\n",
    "    return pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "ohlc_universe = (spark.table('ohlc')\n",
    "  .join(universe, on=['exchange','symbol','interval'], how='inner')\n",
    "  .select('exchange','symbol','interval','open_time','open','high','low','close','volume')\n",
    ")\n",
    "\n",
    "trades_s = (ohlc_universe\n",
    "  .groupBy('exchange','symbol','interval')\n",
    "  .applyInPandas(backtest_group, schema=trade_schema)\n",
    ")\n",
    "\n",
    "display(trades_s.limit(50))\n",
    "print('Trade rows:', trades_s.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write outputs to Delta" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS backtest_trades (\n",
    "  run_id STRING,\n",
    "  exchange STRING,\n",
    "  symbol STRING,\n",
    "  interval STRING,\n",
    "  signal STRING,\n",
    "  atr_mult_stop DOUBLE,\n",
    "  atr_mult_tp DOUBLE,\n",
    "  max_hold_bars INT,\n",
    "  atrp_entry DOUBLE,\n",
    "  atrp_bucket STRING,\n",
    "  entry_time_utc TIMESTAMP,\n",
    "  entry_time_syd TIMESTAMP,\n",
    "  exit_time_utc TIMESTAMP,\n",
    "  entry DOUBLE,\n",
    "  stop DOUBLE,\n",
    "  tp DOUBLE,\n",
    "  exit DOUBLE,\n",
    "  bars_held INT,\n",
    "  outcome STRING,\n",
    "  r_multiple DOUBLE\n",
    ") USING DELTA\n",
    "''')\n",
    "\n",
    "spark.sql('''\n",
    "CREATE TABLE IF NOT EXISTS backtest_results (\n",
    "  run_id STRING,\n",
    "  exchange STRING,\n",
    "  symbol STRING,\n",
    "  interval STRING,\n",
    "  signal STRING,\n",
    "  atr_mult_stop DOUBLE,\n",
    "  atr_mult_tp DOUBLE,\n",
    "  max_hold_bars INT,\n",
    "  atrp_bucket STRING,\n",
    "  n_trades BIGINT,\n",
    "  win_rate DOUBLE,\n",
    "  avg_r DOUBLE,\n",
    "  median_r DOUBLE,\n",
    "  p10_r DOUBLE,\n",
    "  p90_r DOUBLE,\n",
    "  avg_bars_held DOUBLE\n",
    ") USING DELTA\n",
    "''')\n",
    "\n",
    "(trades_s.write.mode('append').saveAsTable('backtest_trades'))\n",
    "\n",
    "results_s = (trades_s\n",
    "  .groupBy('run_id','exchange','symbol','interval','signal','atr_mult_stop','atr_mult_tp','max_hold_bars','atrp_bucket')\n",
    "  .agg(\n",
    "    F.count('*').alias('n_trades'),\n",
    "    F.avg(F.when(F.col('r_multiple') > 0, 1.0).otherwise(0.0)).alias('win_rate'),\n",
    "    F.avg('r_multiple').alias('avg_r'),\n",
    "    F.expr('percentile_approx(r_multiple, 0.5)').alias('median_r'),\n",
    "    F.expr('percentile_approx(r_multiple, 0.1)').alias('p10_r'),\n",
    "    F.expr('percentile_approx(r_multiple, 0.9)').alias('p90_r'),\n",
    "    F.avg('bars_held').alias('avg_bars_held')\n",
    "  )\n",
    ")\n",
    "\n",
    "(results_s.write.mode('append').saveAsTable('backtest_results'))\n",
    "\n",
    "display(results_s.orderBy(F.col('avg_r').desc()).limit(200))\n",
    "print('Wrote run_id', RUN_ID)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
